#!/bin/bash
set -e

# --- 1. VISUAL FEEDBACK ---
GREEN='\033[0;32m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

echo -e "${BLUE}üß† Rhyzomic Intelligence Node (RIN) - Boot Sequence Initiated${NC}"

# --- 2. DEPENDENCY CHECK ---
if ! command -v docker &> /dev/null; then
    echo "Docker not found. Installing..."
    curl -fsSL https://get.docker.com | sh
    sudo usermod -aG docker $USER
    echo "Docker installed. Please re-login to apply user groups."
    exit 1
fi

# --- 3. INFRASTRUCTURE PREP ---
BASE_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
echo -e "${GREEN}üìÇ Verifying biological directory structure...${NC}"

# Create all volume paths
mkdir -p "$BASE_DIR/data"/{open-webui,qdrant,redis,searxng,n8n,litellm}
mkdir -p "$BASE_DIR/config"/{litellm,searxng}
mkdir -p "$BASE_DIR/workflows"

# Fix Permissions (Critical for Redis/Qdrant on Linux)
# Note: 777 is required for Docker volume permissions on many Linux systems
# where the container UIDs don't match host UIDs. This is a known Docker limitation.
chmod 777 "$BASE_DIR/data/redis" "$BASE_DIR/data/qdrant" "$BASE_DIR/data/litellm"

# Fix Permissions for n8n (runs as user 1000 inside container)
chown -R 1000:1000 "$BASE_DIR/data/n8n" 2>/dev/null || chmod 777 "$BASE_DIR/data/n8n"

# --- 4. INTERNAL KEY GENERATION (The Magic Step) ---
# We auto-generate keys if .env doesn't exist. 
# The user only touches this file if they want to add OpenAI/Anthropic keys.

if [ ! -f "$BASE_DIR/.env" ]; then
    echo -e "${GREEN}üîê Generating internal neural secrets...${NC}"
    
    # Generate random high-entropy strings
    LITELLM_KEY="sk-rin-$(openssl rand -hex 12)"
    SEARXNG_KEY=$(openssl rand -hex 32)
    FIRECRAWL_KEY="fc-$(openssl rand -hex 16)"
    
    cat <<EOF > "$BASE_DIR/.env"
# ============================================================================
# RIN Environment Configuration
# Rhyzomic Intelligence Node - Sovereign AI Organism
# ============================================================================
#
# NOTE: This file is AUTO-GENERATED by start.sh with secure internal keys.
# You should NOT need to manually create this file.
# Simply run ./start.sh and it will generate this with random secrets.
#
# ============================================================================

# --- RIN INTERNAL NERVOUS SYSTEM (AUTO-GENERATED) ---
# Do not change these unless you know what you are doing.
# These keys are generated automatically by start.sh for internal service communication.
LITELLM_MASTER_KEY=${LITELLM_KEY}
SEARXNG_SECRET=${SEARXNG_KEY}
FIRECRAWL_API_KEY=${FIRECRAWL_KEY}

# --- FIRECRAWL CONFIGURATION (OPTIONAL) ---
# By default, RIN uses the self-hosted Firecrawl running in Docker.
# To use Firecrawl Cloud API instead, uncomment and set these:
# FIRECRAWL_API_URL=https://api.firecrawl.dev
# FIRECRAWL_API_KEY=fc-your-cloud-api-key-here
# Leave commented to use the self-hosted Docker service.

# --- EXTERNAL API KEYS (USER DEFINED) ---
# Replace these with your actual keys to power the brain.
# These are the only keys you need to manually configure.
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
OPENROUTER_API_KEY=

# --- OPENROUTER WEBHOOK CONFIGURATION (OPTIONAL) ---
# Configure OpenRouter webhook parameters for proper API attribution
# HTTP-Referer: The public URL of your WebUI (leave blank for localhost)
# X-Title: Your application name (defaults to "RIN - Rhyzomic Intelligence Node")
OPENROUTER_SITE_URL=http://localhost:3000
OPENROUTER_APP_NAME=RIN - Rhyzomic Intelligence Node

# --- OPEN WEBUI API (FOR TELEGRAM INTEGRATION) ---
# Used by n8n workflows to query Open WebUI as an API
# Generate in Open WebUI: Settings ‚Üí Account ‚Üí API Keys ‚Üí Create new key
OPENWEBUI_API_KEY=
OPENWEBUI_DEFAULT_MODEL=openrouter/gpt-4o    # Model to use for Telegram queries (uses OpenRouter)

# --- SEARCH & SCRAPING API KEYS (OPTIONAL) ---
# Tavily: AI-optimized search engine (alternative/complement to SearXNG)
# Get your key from: https://tavily.com
TAVILY_API_KEY=

# --- NETWORK ---
# Port configuration for external access
# Change these if the default ports are already in use on your system
PORT_WEBUI=3000        # Open WebUI (Cortex) - Main interface
PORT_LITELLM=4000      # LiteLLM (Router) - AI model routing
PORT_SEARXNG=8080      # SearXNG (Vision) - Search engine
PORT_FIRECRAWL=3002    # FireCrawl (Digestion) - Web scraping
PORT_N8N=5678          # n8n (Reflex) - Workflow automation
PORT_QDRANT=6333       # Qdrant (Memory) - Vector database

# --- SERVICE SELECTION ---
# Services can be disabled to reduce resource usage or if using alternatives
# Set to Y to enable, N to disable
# Note: start.sh will prompt you interactively on first run
ENABLE_FIRECRAWL=Y     # Set to N if using Tavily or other scraping APIs
EOF
    echo "‚úÖ .env created with secure internal keys."
else
    echo "‚úÖ .env already exists. Preserving existing keys."
fi

# --- 4.5 SERVICE SELECTION (INTERACTIVE) ---
# Allow users to choose which optional services to enable
echo ""
echo -e "${BLUE}üéõÔ∏è  Service Selection${NC}"
echo "Choose which services to enable:"
echo ""

# Check if running in non-interactive mode (for CI/CD or scripts)
if [ -t 0 ]; then
    # Interactive mode
    
    # FireCrawl Selection
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    echo "üî• FireCrawl (Web Scraping Engine)"
    echo "   Self-hosted service for extracting content from websites"
    echo "   Alternative: Use Tavily API or other scraping tools via OpenWebUI"
    echo ""
    read -p "   Enable FireCrawl? [Y/n]: " ENABLE_FIRECRAWL
    ENABLE_FIRECRAWL=${ENABLE_FIRECRAWL:-Y}
    
    # Convert to uppercase for comparison
    ENABLE_FIRECRAWL=$(echo "$ENABLE_FIRECRAWL" | tr '[:lower:]' '[:upper:]')
    
    echo ""
else
    # Non-interactive mode - enable all services by default
    echo "‚öôÔ∏è  Non-interactive mode detected. Enabling all services by default."
    ENABLE_FIRECRAWL="Y"
fi

# Store selections in .env for persistence
if grep -q "^ENABLE_FIRECRAWL=" "$BASE_DIR/.env" 2>/dev/null; then
    # Update existing value (use different sed syntax based on OS)
    if [[ "$OSTYPE" == "darwin"* ]]; then
        # macOS requires -i with extension
        sed -i '' "s/^ENABLE_FIRECRAWL=.*/ENABLE_FIRECRAWL=${ENABLE_FIRECRAWL}/" "$BASE_DIR/.env"
    else
        # Linux doesn't need extension
        sed -i "s/^ENABLE_FIRECRAWL=.*/ENABLE_FIRECRAWL=${ENABLE_FIRECRAWL}/" "$BASE_DIR/.env"
    fi
else
    # Add new value
    echo "" >> "$BASE_DIR/.env"
    echo "# --- SERVICE SELECTION ---" >> "$BASE_DIR/.env"
    echo "# Services can be disabled to reduce resource usage" >> "$BASE_DIR/.env"
    echo "ENABLE_FIRECRAWL=${ENABLE_FIRECRAWL}" >> "$BASE_DIR/.env"
fi

# Export for docker-compose profiles
export ENABLE_FIRECRAWL

# --- 5. CONFIGURATION INJECTION ---

# --- 5.1 SYNC OPENROUTER MODELS ---
echo -e "${BLUE}üîÑ Synchronizing OpenRouter models...${NC}"
if [ -f "$BASE_DIR/scripts/sync_openrouter_models.py" ]; then
    # Try to sync models from OpenRouter API
    # Capture errors to a temporary file for better debugging
    SYNC_ERROR=$(mktemp)
    if python3 "$BASE_DIR/scripts/sync_openrouter_models.py" 2>"$SYNC_ERROR"; then
        rm -f "$SYNC_ERROR"
    else
        echo "‚ö†Ô∏è  Could not fetch latest models from OpenRouter API"
        echo "   Using static model configuration from config/litellm/config.yaml"
        echo "   This is normal if you haven't set OPENROUTER_API_KEY yet"
        
        # Show error details if available
        if [ -s "$SYNC_ERROR" ]; then
            echo ""
            echo "   Error details (for troubleshooting):"
            head -5 "$SYNC_ERROR" | sed 's/^/   /'
            echo "   Full error log saved to: $SYNC_ERROR"
        else
            rm -f "$SYNC_ERROR"
        fi
    fi
else
    echo "‚ö†Ô∏è  Model sync script not found, using static configuration"
fi

# Generate SearXNG Settings (Prevents Crash Loop)
if [ ! -f "$BASE_DIR/config/searxng/settings.yml" ]; then
    # We pull the key back out of .env to populate the config
    LOADED_SEARX_KEY=$(grep "^SEARXNG_SECRET=" "$BASE_DIR/.env" | cut -d '=' -f2 | tr -d ' ')
    
    # Check if we have a template with academic engines
    if [ -f "$BASE_DIR/config/searxng/settings.yml.example" ]; then
        # Use the template and inject the secret key
        sed "s/REPLACE_WITH_RANDOM_SECRET/${LOADED_SEARX_KEY}/" "$BASE_DIR/config/searxng/settings.yml.example" > "$BASE_DIR/config/searxng/settings.yml"
        echo "‚úÖ SearXNG configured with academic search engines (Google Scholar, arXiv, PubMed, etc.)"
    else
        # Fallback to basic config
        cat <<EOF > "$BASE_DIR/config/searxng/settings.yml"
use_default_settings: true
server:
  secret_key: "${LOADED_SEARX_KEY}"
  bind_address: "0.0.0.0"
  image_proxy: true
  limiter: false
search:
  formats:
    - html
    - json
EOF
    fi
fi

# --- 6. DNS FIX (Azure/Cloud Specific) ---
# Ensures containers can talk to the outside world
# Only applies if Docker daemon config doesn't already have DNS settings
if [ ! -f /etc/docker/daemon.json ] || ! grep -q '"dns"' /etc/docker/daemon.json 2>/dev/null; then
    echo -e "${BLUE}üîß Patching Docker DNS...${NC}"
    sudo mkdir -p /etc/docker
    # Merge with existing config if present, otherwise create new
    if [ -f /etc/docker/daemon.json ]; then
        echo "‚ö†Ô∏è  Existing Docker daemon.json found. Please manually add DNS settings if needed."
    else
        echo '{"dns": ["1.1.1.1", "8.8.8.8"]}' | sudo tee /etc/docker/daemon.json > /dev/null
        sudo systemctl restart docker
        sleep 3 # Wait for Docker to wake up
    fi
fi

# --- 7. LAUNCH ---
echo -e "${GREEN}üöÄ Igniting the Organism...${NC}"

# Verify docker-compose.yml exists
if [ ! -f "$BASE_DIR/docker-compose.yml" ]; then
    echo "‚ùå Error: docker-compose.yml not found in $BASE_DIR"
    exit 1
fi

# Verify Docker is running
if ! docker info >/dev/null 2>&1; then
    echo "‚ùå Error: Docker is not running. Please start Docker and try again."
    exit 1
fi

# Build docker compose command with selected profiles
COMPOSE_PROFILES=""
if [ "$ENABLE_FIRECRAWL" = "Y" ]; then
    COMPOSE_PROFILES="--profile firecrawl"
    echo "‚úì Enabling FireCrawl services"
fi

# Launch services with selected profiles
if [ -n "$COMPOSE_PROFILES" ]; then
    docker compose $COMPOSE_PROFILES up -d --remove-orphans
else
    docker compose up -d --remove-orphans
fi

# --- 8. AUTO-REGISTER TOOLS ---
echo -e "${BLUE}üîß Registering tools in Open WebUI...${NC}"

# Wait for Open WebUI to be healthy (max 60 seconds)
MAX_WAIT=60
WAITED=0
while [ $WAITED -lt $MAX_WAIT ]; do
    if docker exec rin-cortex test -f /app/backend/data/webui.db 2>/dev/null; then
        break
    fi
    sleep 2
    WAITED=$((WAITED + 2))
done

if [ $WAITED -ge $MAX_WAIT ]; then
    echo "‚ö†Ô∏è  Timeout waiting for Open WebUI database. Tools may need manual registration."
else
    # Run the tool registration script
    if [ -f "$BASE_DIR/tools/register_tools.py" ]; then
        docker exec rin-cortex python3 /app/backend/data/tools/register_tools.py 2>/dev/null || echo "‚ö†Ô∏è  Tool registration script failed. You may need to register tools manually."
    fi
fi

# --- 9. AUTO-IMPORT N8N WORKFLOWS ---
echo -e "${BLUE}üîÑ Importing n8n workflows...${NC}"

# Wait for n8n to be ready (max 30 seconds)
MAX_WAIT=30
WAITED=0
while [ $WAITED -lt $MAX_WAIT ]; do
    if docker exec rin-reflex-automation test -f /home/node/.n8n/database.sqlite 2>/dev/null; then
        break
    fi
    sleep 2
    WAITED=$((WAITED + 2))
done

if [ $WAITED -ge $MAX_WAIT ]; then
    echo "‚ö†Ô∏è  Timeout waiting for n8n. Workflows may need manual import."
else
    # Check if workflows already imported
    WORKFLOW_LIST=$(docker exec rin-reflex-automation n8n list:workflow 2>/dev/null || echo "")
    # Drop potential header line and count only non-empty lines as actual workflows
    # Extract only numeric characters and use first number found, default to 0
    WORKFLOW_COUNT=$(printf "%s" "$WORKFLOW_LIST" | sed '1d' | grep -c '[^[:space:]]' 2>/dev/null | grep -o '[0-9]*' | head -1)
    WORKFLOW_COUNT=${WORKFLOW_COUNT:-0}
    if [ "$WORKFLOW_COUNT" -gt 0 ] 2>/dev/null; then
        echo "  ‚ÑπÔ∏è  $WORKFLOW_COUNT workflows already present"
    else
        # Import workflows from /workflows directory
        echo "  Importing workflows from /workflows..."
        IMPORT_OUTPUT=$(docker exec rin-reflex-automation n8n import:workflow --separate --input=/workflows/ 2>&1)
        IMPORT_STATUS=$?
        echo "$IMPORT_OUTPUT" | grep -v "Could not find workflow" | grep -v "Could not remove webhooks" || true
        if [ $IMPORT_STATUS -eq 0 ]; then
            echo "  ‚úÖ Workflows imported"
        else
            echo "  ‚ùå Workflow import failed (exit code $IMPORT_STATUS). See output above for details."
        fi
    fi
fi

# Load port configuration from .env to display in output
if [ -f "$BASE_DIR/.env" ]; then
    # Use a safer approach to export variables, avoiding comments and special characters
    while IFS='=' read -r key value; do
        # Skip empty lines and comments
        [[ -z "$key" || "$key" =~ ^[[:space:]]*# ]] && continue
        # Only export PORT_ and ENABLE_ variables
        if [[ "$key" =~ ^PORT_ ]] || [[ "$key" =~ ^ENABLE_ ]]; then
            export "$key=$value"
        fi
    done < <(grep -E '^(PORT_|ENABLE_)' "$BASE_DIR/.env" 2>/dev/null || true)
fi

# Use loaded values or defaults
PORT_WEBUI=${PORT_WEBUI:-3000}
PORT_N8N=${PORT_N8N:-5678}
PORT_SEARXNG=${PORT_SEARXNG:-8080}
PORT_FIRECRAWL=${PORT_FIRECRAWL:-3002}
PORT_LITELLM=${PORT_LITELLM:-4000}

echo ""
echo -e "${GREEN}‚úÖ RIN IS ALIVE.${NC}"
echo ""
echo "=== Post-Deployment Verification ==="
echo "Verify the biological subsystems are active:"
echo ""
echo "üß† Cortex (UI):        http://localhost:${PORT_WEBUI}      (Open WebUI login screen)"
echo "üîÑ Reflex (n8n):       http://localhost:${PORT_N8N}      (n8n workflow editor)"
echo "üëÅÔ∏è  Sensorium:         http://localhost:${PORT_SEARXNG}      (SearXNG search bar)"
if [ "$ENABLE_FIRECRAWL" = "Y" ]; then
    echo "üî• Digestion:          http://localhost:${PORT_FIRECRAWL}      (FireCrawl API - returns {\"status\":\"ok\"})"
else
    echo "üî• Digestion:          [DISABLED] (Use Tavily or other APIs in OpenWebUI)"
fi
echo "üö¶ Router:             http://localhost:${PORT_LITELLM}/health (LiteLLM health status)"
echo ""
echo "=== Tools (Auto-Registered) ==="
echo "‚úÖ FireCrawl Scraper   - Web scraping with headless browser"
echo "‚úÖ Tavily Search       - AI-optimized web search"
echo "‚úÖ SearXNG Search      - Academic search (Google Scholar, arXiv, PubMed)"
echo "‚úÖ Qdrant Memory       - Long-term RAG memory"
echo "‚úÖ n8n Reflex          - Synaptic Bridge (trigger_reflex + query_workflow)"
echo ""
echo "View tools: http://localhost:${PORT_WEBUI} ‚Üí Workspace ‚Üí Tools"
echo ""
echo "=== n8n Workflows (Auto-Imported) ==="
echo "üî• Reflex Workflows (fire-and-forget via trigger_reflex):"
echo "   - send-email        : Send emails via SMTP"
echo "   - slack-notify      : Post to Slack channels"
echo "   - telegram-send     : Send Telegram messages"
echo ""
echo "üß† Cognitive Workflows (data retrieval via query_workflow):"
echo "   - research          : Deep research with sources"
echo "   - openwebui-action  : General-purpose router"
echo ""
echo "‚è∞ Scheduled Workflows (autonomous):"
echo "   - Morning Briefing  : 8 AM daily news summary"
echo "   - RSS Monitor       : Every 6 hours feed digest"
echo "   - Daily Report      : 6 PM intelligence report"
echo ""
echo "Manage workflows: http://localhost:${PORT_N8N}"
echo ""
echo "=== Next Steps ==="
echo "1. Add API keys: nano .env (add OPENAI_API_KEY or ANTHROPIC_API_KEY)"
echo "2. Restart to apply: ./start.sh"
echo "3. Activate scheduled workflows in n8n (toggle ON in workflow editor)"
echo ""
echo "=== Telegram Integration (Optional) ==="
echo "For Telegram research assistant:"
echo "1. Create a Telegram bot: https://t.me/BotFather"
echo "2. Add TELEGRAM_BOT_TOKEN to .env"
echo "3. Generate Open WebUI API key: ./scripts/generate_api_key.sh"
echo "4. Import: workflows/telegram_research_assistant.json"
echo ""
echo "For Azure voice assistant, add to .env:"
echo "   AZURE_OPENAI_RESOURCE_NAME, AZURE_OPENAI_API_KEY, AZURE_WHISPER_DEPLOYMENT_NAME"
