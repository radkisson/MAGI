model_list:
  # ============================================================================
  # OpenAI Models (Direct API)
  # ============================================================================
  
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
    model_info:
      mode: chat
      supports_function_calling: true
      supports_vision: true
  
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
    model_info:
      mode: chat
      supports_function_calling: true
      supports_vision: true
  
  # ============================================================================
  # Anthropic Models (Direct API)
  # ============================================================================
  
  - model_name: claude-3-5-sonnet
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      temperature: 0.7
      max_tokens: 8192
      top_p: 1.0
    model_info:
      mode: chat
      supports_function_calling: true
      supports_vision: true
  
  - model_name: claude-3-5-haiku
    litellm_params:
      model: anthropic/claude-3-5-haiku-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
      temperature: 0.7
      max_tokens: 8192
      top_p: 1.0
    model_info:
      mode: chat
      supports_function_calling: true
      supports_vision: true
  
  # ============================================================================
  # OpenRouter Integration - Full Model Marketplace Access
  # ============================================================================
  
  # OpenRouter: OpenAI Models
  - model_name: openrouter/gpt-4o
    litellm_params:
      model: openrouter/openai/gpt-4o
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
      extra_headers:
        HTTP-Referer: os.environ/OPENROUTER_SITE_URL
        X-Title: os.environ/OPENROUTER_APP_NAME
    model_info:
      mode: chat
      supports_function_calling: true
      supports_vision: true
  
  - model_name: openrouter/gpt-4-turbo
    litellm_params:
      model: openrouter/openai/gpt-4-turbo
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
      extra_headers:
        HTTP-Referer: os.environ/OPENROUTER_SITE_URL
        X-Title: os.environ/OPENROUTER_APP_NAME
    model_info:
      mode: chat
      supports_function_calling: true
      supports_vision: true
  
  # OpenRouter: Anthropic Models
  - model_name: openrouter/claude-3-5-sonnet
    litellm_params:
      model: openrouter/anthropic/claude-3.5-sonnet
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.7
      max_tokens: 8192
      top_p: 1.0
      extra_headers:
        HTTP-Referer: os.environ/OPENROUTER_SITE_URL
        X-Title: os.environ/OPENROUTER_APP_NAME
    model_info:
      mode: chat
      supports_function_calling: true
  
  - model_name: openrouter/claude-3-opus
    litellm_params:
      model: openrouter/anthropic/claude-3-opus
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
      extra_headers:
        HTTP-Referer: os.environ/OPENROUTER_SITE_URL
        X-Title: os.environ/OPENROUTER_APP_NAME
    model_info:
      mode: chat
      supports_function_calling: true
      supports_vision: true
  
  # OpenRouter: Meta Llama Models
  - model_name: openrouter/llama-3.1-405b
    litellm_params:
      model: openrouter/meta-llama/llama-3.1-405b-instruct
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
      extra_headers:
        HTTP-Referer: os.environ/OPENROUTER_SITE_URL
        X-Title: os.environ/OPENROUTER_APP_NAME
    model_info:
      mode: chat
  
  - model_name: openrouter/llama-3.1-70b
    litellm_params:
      model: openrouter/meta-llama/llama-3.1-70b-instruct
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
      extra_headers:
        HTTP-Referer: os.environ/OPENROUTER_SITE_URL
        X-Title: os.environ/OPENROUTER_APP_NAME
    model_info:
      mode: chat
  
  # OpenRouter: Google Models
  - model_name: openrouter/gemini-pro
    litellm_params:
      model: openrouter/google/gemini-pro-1.5
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.7
      max_tokens: 8192
      top_p: 1.0
      extra_headers:
        HTTP-Referer: os.environ/OPENROUTER_SITE_URL
        X-Title: os.environ/OPENROUTER_APP_NAME
    model_info:
      mode: chat
      supports_vision: true
  
  - model_name: openrouter/gemini-flash
    litellm_params:
      model: openrouter/google/gemini-flash-1.5
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.7
      max_tokens: 8192
      top_p: 1.0
      extra_headers:
        HTTP-Referer: os.environ/OPENROUTER_SITE_URL
        X-Title: os.environ/OPENROUTER_APP_NAME
    model_info:
      mode: chat
      supports_vision: true
  
  # OpenRouter: Mistral Models
  - model_name: openrouter/mistral-large
    litellm_params:
      model: openrouter/mistralai/mistral-large
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
      extra_headers:
        HTTP-Referer: os.environ/OPENROUTER_SITE_URL
        X-Title: os.environ/OPENROUTER_APP_NAME
    model_info:
      mode: chat
  
  - model_name: openrouter/mixtral-8x7b
    litellm_params:
      model: openrouter/mistralai/mixtral-8x7b-instruct
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
      extra_headers:
        HTTP-Referer: os.environ/OPENROUTER_SITE_URL
        X-Title: os.environ/OPENROUTER_APP_NAME
    model_info:
      mode: chat
  
  # OpenRouter: Cohere Models
  - model_name: openrouter/command-r-plus
    litellm_params:
      model: openrouter/cohere/command-r-plus
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
      extra_headers:
        HTTP-Referer: os.environ/OPENROUTER_SITE_URL
        X-Title: os.environ/OPENROUTER_APP_NAME
    model_info:
      mode: chat
  
  # OpenRouter: Perplexity Models
  - model_name: openrouter/perplexity-online
    litellm_params:
      model: openrouter/perplexity/llama-3.1-sonar-large-128k-online
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.7
      max_tokens: 4096
      top_p: 1.0
      extra_headers:
        HTTP-Referer: os.environ/OPENROUTER_SITE_URL
        X-Title: os.environ/OPENROUTER_APP_NAME
    model_info:
      mode: chat

# ============================================================================
# Router Settings - Enhanced with Fallback Chains
# ============================================================================
router_settings:
  routing_strategy: usage-based-routing-v2
  enable_pre_call_checks: true
  allowed_fails: 3
  cooldown_time: 60
  num_retries: 2
  timeout: 60
  fallbacks:
  - gpt-4o:
    - openrouter/openai-gpt-4o
    - claude-3-5-sonnet
    - openrouter/meta-llama-llama-3.1-405b-instruct
  - claude-3-5-sonnet:
    - openrouter/anthropic-claude-3-5-sonnet-20241022
    - gpt-4o
    - openrouter/openai-gpt-4-turbo
  - gpt-4o-mini:
    - claude-3-5-haiku
    - openrouter/google-gemini-flash-1.5
    - openrouter/mistralai-mixtral-8x7b-instruct
general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  set_verbose: false
  alerting:
  - webhook
  cache:
    type: redis
    host: redis
    port: 6379
litellm_settings:
  drop_params: true
  default_max_tokens: 4096
  default_temperature: 0.7
  default_top_p: 1.0
