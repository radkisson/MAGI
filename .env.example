# Environment Configuration for RIN
# Copy this file to .env and configure your settings

# API Keys (for LLM providers)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# LLM Configuration
LLM_PROVIDER=openai  # openai, anthropic, or local
LLM_MODEL=gpt-4  # Model to use
LLM_TEMPERATURE=0.7

# Vector Database Configuration
VECTOR_DB_TYPE=chroma  # chroma, pinecone, qdrant, or local
VECTOR_DB_PATH=./data/vectors  # Path for local vector storage
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment

# Memory Configuration
MEMORY_MAX_SIZE=10000  # Maximum number of memories to store
MEMORY_EMBEDDING_MODEL=text-embedding-ada-002

# Sensors Configuration
BROWSER_HEADLESS=true
BROWSER_TIMEOUT=30000  # milliseconds
API_REQUEST_TIMEOUT=30  # seconds
MAX_CONCURRENT_REQUESTS=5

# Reflexes Configuration
MAX_WORKFLOW_ACTIONS=50
ACTION_TIMEOUT=60  # seconds

# Logging
LOG_LEVEL=INFO  # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_FILE=./data/logs/rin.log

# Server Configuration (if running as API)
HOST=0.0.0.0
PORT=8000

# Security
ENABLE_AUTH=false
API_KEY=your_api_key_here

# Data Storage
DATA_DIR=./data
MEMORY_DIR=./data/memory
CACHE_DIR=./data/cache
