# ============================================================================
# MAGI Environment Configuration
# Multi-Agent General Intelligence - Sovereign AI Organism
# ============================================================================
#
# NOTE: This file is AUTO-GENERATED by start.sh with secure internal keys.
# You should NOT need to manually create this file.
# Simply run ./start.sh and it will generate this with random secrets.
#
# ============================================================================

# --- MAGI INTERNAL NERVOUS SYSTEM (AUTO-GENERATED) ---
# Do not change these unless you know what you are doing.
# These keys are generated automatically by start.sh for internal service communication.
LITELLM_MASTER_KEY=sk-magi-XXXXXXXXXXXXXXXXXXXXXXXX
SEARXNG_SECRET=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
FIRECRAWL_API_KEY=fc-XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

# --- FIRECRAWL CONFIGURATION (OPTIONAL) ---
# By default, MAGI uses the self-hosted Firecrawl running in Docker.
# To use Firecrawl Cloud API instead, uncomment and set these:
# FIRECRAWL_API_URL=https://api.firecrawl.dev
# FIRECRAWL_API_KEY=fc-your-cloud-api-key-here
# Leave commented to use the self-hosted Docker service.

# --- EXTERNAL API KEYS (USER DEFINED) ---
# Replace these with your actual keys to power the brain.
# These are the only keys you need to manually configure.
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
OPENROUTER_API_KEY=

# --- AZURE OPENAI CONFIGURATION (OPTIONAL) ---
# Configure Azure OpenAI deployments for enterprise use
# Models are auto-injected into LiteLLM config on startup
# Format: AZURE_OPENAI_MODELS is a comma-separated list of model configs
# Each config format: deployment_name:model_name (e.g., gpt4o-deployment:gpt-4o)
#
# Example with multiple models:
# AZURE_OPENAI_MODELS=my-gpt4o:gpt-4o,my-gpt4o-mini:gpt-4o-mini,my-o1:o1-preview
#
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_VERSION=2024-08-01-preview
AZURE_OPENAI_MODELS=

# --- OPENROUTER WEBHOOK CONFIGURATION (OPTIONAL) ---
# Configure OpenRouter webhook parameters for proper API attribution
# HTTP-Referer: The public URL of your WebUI (leave blank for localhost)
# X-Title: Your application name (defaults to "MAGI - Multi-Agent General Intelligence")
OPENROUTER_SITE_URL=http://localhost:3000
OPENROUTER_APP_NAME=MAGI - Multi-Agent General Intelligence

# --- OPENROUTER MODEL LIMITING (OPTIONAL) ---
# Limit the number of OpenRouter models to sync and display
# This improves performance by reducing the number of models in config
# Recommended values: 10, 25, 50, 75 (default: 50)
# Set to 0 to sync all available models. If not defined, defaults to 50.
OPENROUTER_MODEL_LIMIT=50

# --- OPEN WEBUI API (FOR TELEGRAM INTEGRATION) ---
# Used by n8n workflows to query Open WebUI as an API
# Generate in Open WebUI: Settings → Account → API Keys → Create new key
OPENWEBUI_API_KEY=
OPENWEBUI_DEFAULT_MODEL=openrouter/gpt-4o    # Model to use for Telegram queries (uses OpenRouter)

# --- DEFAULT SYSTEM PROMPT (MEMORY INTEGRATION) ---
# This prompt is injected into all conversations to enable memory features
# Set ENABLE_PERSISTENT_CONFIG=false if changing this after first run
# Leave empty for no default prompt, or customize as needed
DEFAULT_SYSTEM_PROMPT=You are MAGI (Multi-Agent General Intelligence), an AI assistant with long-term memory. You have access to memory tools: recall_memory(query, limit) to search past conversations and stored facts, and store_memory(content, metadata) to save important information. Always use recall_memory when users ask about past discussions or preferences. Store important facts, preferences, and decisions using store_memory. Reference memories naturally and confirm when storing information.

# --- AZURE COHERE RERANKER (OPTIONAL) ---
# Azure AI Cohere Rerank for improved memory recall accuracy
# Used by qdrant_memory.py to rerank search results
# Get endpoint from Azure AI Foundry: https://ai.azure.com
AZURE_COHERE_RERANK_ENDPOINT=
AZURE_COHERE_RERANK_API_KEY=
AZURE_COHERE_RERANK_MODEL=Cohere-rerank-v4.0-fast

# --- AZURE OPENAI EMBEDDING (OPTIONAL) ---
# Azure OpenAI embedding model for memory storage
# Used by qdrant_memory.py for semantic embeddings (set EMBEDDING_TYPE=azure in tool)
# Dimension: 1536 for text-embedding-3-small
AZURE_EMBEDDING_ENDPOINT=
AZURE_EMBEDDING_API_KEY=
AZURE_EMBEDDING_DEPLOYMENT=text-embedding-3-small

# --- SEARCH & SCRAPING API KEYS (OPTIONAL) ---
# Tavily: AI-optimized search engine (alternative/complement to SearXNG)
# Get your key from: https://tavily.com
TAVILY_API_KEY=

# --- NETWORK ---
# Port configuration for external access
# Change these if the default ports are already in use on your system
PORT_WEBUI=3000        # Open WebUI (Cortex) - Main interface
PORT_LITELLM=4000      # LiteLLM (Router) - AI model routing
PORT_SEARXNG=8080      # SearXNG (Vision) - Search engine
PORT_FIRECRAWL=3002    # FireCrawl (Digestion) - Web scraping
PORT_N8N=5678          # n8n (Reflex) - Workflow automation
PORT_QDRANT=6333       # Qdrant (Memory) - Vector database
PORT_MCP_BRIDGE=9000   # MCP Bridge (Sequential Thinking) - Model Context Protocol bridge
PORT_YOUTUBE_MCP=9001  # YouTube MCP (YouTube Transcript) - Video subtitle extraction
PORT_JUPYTER=8888      # Jupyter Lab - Code execution and data analysis

# --- SERVICE SELECTION ---
# Services can be disabled to reduce resource usage or if using alternatives
# Set to Y to enable, N to disable
# Note: start.sh will prompt you interactively on first run
ENABLE_FIRECRAWL=Y     # Set to N if using Tavily or other scraping APIs

# --- HTTPS/TLS CONFIGURATION (OPTIONAL) ---
# Enable HTTPS for services that support it
# Set to 'true' to enable HTTPS, 'false' to use HTTP (default)
# Note: HTTPS requires a reverse proxy (nginx, Traefik, Caddy) for SSL termination
# See docs/HTTPS_CONFIGURATION.md for setup instructions
ENABLE_HTTPS=false

# --- AUTOMATIC HTTPS WITH LET'S ENCRYPT (RECOMMENDED) ---
# Enable automatic HTTPS with Caddy reverse proxy and Let's Encrypt
# Set to 'true' to enable automatic certificate management
# Requires a valid domain name and ports 80/443 accessible from the internet
ENABLE_AUTO_HTTPS=false

# Domain name for automatic HTTPS (required if ENABLE_AUTO_HTTPS=true)
# Must point to this server's public IP address
MAGI_DOMAIN=

# Admin email for Let's Encrypt notifications (required if ENABLE_AUTO_HTTPS=true)
# You'll receive alerts before certificate expiration
MAGI_ADMIN_EMAIL=

# SSL Certificate paths (required if ENABLE_HTTPS=true and ENABLE_AUTO_HTTPS=false)
# You can use self-signed certificates for development or proper CA-signed certificates for production
# Generate self-signed certificates with: ./scripts/generate-certs.sh
SSL_CERT_PATH=./config/ssl/cert.pem
SSL_KEY_PATH=./config/ssl/key.pem
SSL_CA_PATH=./config/ssl/ca.pem

# --- TAILSCALE HTTPS CONFIGURATION (OPTIONAL) ---
# Tailscale Serve provides zero-config HTTPS for your Tailscale network
# Run ./rin setup-tailscale to configure automatically
# These are set automatically by the setup script:
# ENABLE_TAILSCALE_HTTPS=true
# TAILSCALE_DOMAIN=your-hostname.your-tailnet.ts.net
# WEBUI_URL=https://your-hostname.your-tailnet.ts.net
# N8N_PATH=/n8n
# N8N_EDITOR_BASE_URL=https://your-hostname.your-tailnet.ts.net/n8n/
# JUPYTER_BASE_URL=/jupyter
# Note: The setup script also sets ENABLE_PERSISTENT_CONFIG=false
# to ensure WEBUI_URL changes take effect (see OpenWebUI configuration below)

# --- OPENWEBUI CONFIGURATION (OPTIONAL) ---
# Base URL where OpenWebUI is accessible (for frontend-backend communication)
# Leave empty for default (http://localhost:3000)
# Set this when using Tailscale, reverse proxy, or accessing from a domain
# Example: https://your-domain.com or https://your-hostname.ts.net
WEBUI_URL=

# Disable persistent config to allow environment variable changes to take effect
# Set to 'false' when you need to change WEBUI_URL or other persistent settings
# Default: true (config is stored in database on first launch)
ENABLE_PERSISTENT_CONFIG=true

# --- JUPYTER LAB CONFIGURATION (OPTIONAL) ---
# Authentication token for Jupyter Lab
# Leave empty for no authentication (suitable for local development only)
# For production or network-accessible deployments, set to a secure random string
# Generate a token with: openssl rand -hex 32
JUPYTER_TOKEN=

# --- INITIAL ADMIN CREDENTIALS (OPTIONAL) ---
# These credentials are used to create initial admin accounts for OpenWebUI and n8n
# If left blank, you will be prompted during first startup
# Email must be valid format, password must be at least 8 characters
# After first login, change your passwords using: ./rin reset-password <service>
MAGI_ADMIN_EMAIL=
MAGI_ADMIN_PASSWORD=
