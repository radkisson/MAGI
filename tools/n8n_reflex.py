"""
n8n Reflex Tool for Open WebUI

This tool creates the "Synaptic Bridge" between the Cortex (Open WebUI) and
the Reflex Arc (n8n), allowing the brain to trigger autonomous workflows.

Two Operational Modes:
- trigger_reflex(): Fire-and-forget actions (email, notifications, start long tasks)
- query_workflow(): Cognitive loop - wait for and return data (research, lookups)

Use Cases:
- "RIN, send an email to my team" ‚Üí trigger_reflex (fire-and-forget)
- "RIN, research this company and tell me what you find" ‚Üí query_workflow (wait for data)
"""

import os
import json
import time
import re
import threading
import requests
from typing import Callable, Any
from pydantic import BaseModel, Field


class Valves(BaseModel):
    """Configuration valves for n8n Reflex integration (tunable via UI)"""

    N8N_WEBHOOK_URL: str = Field(
        default_factory=lambda: _get_n8n_webhook_url(),
        description="n8n webhook base URL (default: internal Docker DNS, auto-detects HTTP/HTTPS)"
    )
    COGNITIVE_TIMEOUT: int = Field(
        default=300,
        description="Timeout in seconds for cognitive (blocking) workflows (default: 300s = 5 minutes)"
    )
    REFLEX_TIMEOUT: int = Field(
        default=10,
        description="Timeout in seconds for reflex (fire-and-forget) workflows (default: 10s)"
    )
    PULSE_INTERVAL: int = Field(
        default=15,
        description="Interval in seconds between 'waiting' status updates for cognitive workflows"
    )


def _get_n8n_webhook_url() -> str:
    """Get n8n webhook URL, auto-detecting HTTP or HTTPS based on configuration."""
    enable_https = os.getenv("ENABLE_HTTPS", "false").lower() == "true"
    protocol = "https" if enable_https else "http"
    return os.getenv("N8N_WEBHOOK_URL", f"{protocol}://rin-reflex-automation:5678/webhook")


class Tools:
    """Open WebUI Tool: Synaptic Bridge to n8n Workflow Automation

    Provides two distinct modes of operation:
    - trigger_reflex: Fire-and-forget (actions like email, notifications)
    - query_workflow: Cognitive loop (research, data retrieval - waits for response)
    """

    def __init__(self):
        self.valves = Valves()

    def _validate_workflow_id(self, workflow_id: str) -> tuple[bool, str]:
        """Validate workflow_id to ensure it's safe for URL construction."""
        if not workflow_id:
            return False, "Workflow ID cannot be empty"

        # Only allow alphanumeric characters, hyphens, and underscores
        if not re.match(r'^[a-zA-Z0-9_-]+$', workflow_id):
            return False, "Workflow ID can only contain letters, numbers, hyphens, and underscores"

        return True, ""

    def _parse_payload(self, payload: str) -> dict:
        """Parse payload string into structured data."""
        try:
            if payload and (payload.startswith('{') or payload.startswith('[')):
                return {"data": json.loads(payload)}
            else:
                return {"data": payload}
        except (json.JSONDecodeError, AttributeError):
            return {"data": payload}

    def _emit_status(self, emitter: Callable, description: str, done: bool = False):
        """Emit a status update to the UI."""
        if emitter:
            emitter({
                "type": "status",
                "data": {
                    "description": description,
                    "done": done,
                },
            })

    def trigger_reflex(
        self,
        workflow_id: str,
        payload: str,
        __user__: dict = {},
        __event_emitter__: Callable[[dict], Any] = None,
    ) -> str:
        """
        Fire-and-forget: Triggers an autonomous action in the Nervous System (n8n).

        Use this for ACTIONS that don't need to return data to the conversation:
        - Sending emails
        - Posting notifications (Slack, Telegram)
        - Starting long-running background tasks
        - Triggering external integrations

        The workflow runs autonomously in the background. This function returns
        immediately after n8n acknowledges the request.

        Args:
            workflow_id: The webhook path of the workflow (e.g., 'send-email', 'slack-notify')
            payload: Data to send to the workflow (string or JSON string)

        Returns:
            Confirmation that the reflex was triggered

        Examples:
            workflow_id: "send-email"
            payload: '{"to": "boss@company.com", "subject": "Report", "body": "..."}'

            workflow_id: "slack-notify"
            payload: '{"channel": "#alerts", "message": "Task completed"}'
        """

        # Validate workflow_id
        is_valid, error_msg = self._validate_workflow_id(workflow_id)
        if not is_valid:
            self._emit_status(__event_emitter__, "‚ùå Invalid workflow ID", done=True)
            return f"‚ùå Invalid Workflow ID: {error_msg}"

        self._emit_status(__event_emitter__, f"‚ö° Triggering reflex: {workflow_id}")

        url = f"{self.valves.N8N_WEBHOOK_URL}/{workflow_id}"
        data = self._parse_payload(payload)

        try:
            response = requests.post(
                url,
                json=data,
                headers={"Content-Type": "application/json"},
                timeout=self.valves.REFLEX_TIMEOUT
            )

            self._emit_status(__event_emitter__, "‚úÖ Reflex triggered", done=True)

            if response.status_code == 200:
                return (
                    f"‚úÖ Reflex Arc activated.\n\n"
                    f"**Workflow**: `{workflow_id}`\n"
                    f"**Status**: Running autonomously in the Nervous System\n\n"
                    f"The action has been initiated and will complete in the background."
                )
            else:
                return (
                    f"‚ö†Ô∏è Reflex response: {response.status_code}\n\n"
                    f"The workflow may not have triggered correctly.\n"
                    f"Check n8n dashboard: http://localhost:5678"
                )

        except requests.exceptions.Timeout:
            self._emit_status(__event_emitter__, "‚è±Ô∏è Reflex acknowledged (async)", done=True)
            return (
                f"‚è±Ô∏è Reflex initiated.\n\n"
                f"**Workflow**: `{workflow_id}`\n"
                f"**Status**: Running (did not wait for completion)\n\n"
                f"The workflow is executing. Check n8n for progress."
            )

        except requests.exceptions.ConnectionError:
            self._emit_status(__event_emitter__, "‚ùå Connection failed", done=True)
            return (
                f"‚ùå Nervous System Failure\n\n"
                f"Cannot reach n8n at `{url}`\n\n"
                f"**Troubleshooting**:\n"
                f"1. Check if n8n is running: `docker ps | grep rin-reflex`\n"
                f"2. Restart n8n: `docker restart rin-reflex-automation`"
            )

        except Exception as e:
            self._emit_status(__event_emitter__, "‚ùå Error", done=True)
            return f"‚ùå Synaptic Bridge Error: {str(e)}"

    def query_workflow(
        self,
        workflow_id: str,
        payload: str,
        __user__: dict = {},
        __event_emitter__: Callable[[dict], Any] = None,
    ) -> str:
        """
        Cognitive Loop: Queries a workflow and waits for the response data.

        Use this when you need DATA back from n8n to continue the conversation:
        - Research tasks (search, scrape, synthesize)
        - Data lookups (API queries, database reads)
        - Any workflow where the AI needs the result to answer the user

        This function BLOCKS until n8n completes and returns the result.
        The n8n workflow MUST use "Respond to Webhook" node to return data.

        Args:
            workflow_id: The webhook path of the workflow (e.g., 'research', 'lookup')
            payload: Query data to send to the workflow (string or JSON string)

        Returns:
            Raw JSON response from the workflow (for the LLM to interpret)

        Examples:
            workflow_id: "research"
            payload: "Tesla Inc quarterly earnings"

            workflow_id: "company-lookup"
            payload: '{"company": "OpenAI", "fields": ["funding", "employees"]}'
        """

        # Validate workflow_id
        is_valid, error_msg = self._validate_workflow_id(workflow_id)
        if not is_valid:
            self._emit_status(__event_emitter__, "‚ùå Invalid workflow ID", done=True)
            return f"‚ùå Invalid Workflow ID: {error_msg}"

        self._emit_status(__event_emitter__, f"üß† Initiating cognitive query: {workflow_id}")

        url = f"{self.valves.N8N_WEBHOOK_URL}/{workflow_id}"
        data = self._parse_payload(payload)

        # Use requests with streaming to allow pulse updates
        start_time = time.time()
        pulse_interval = self.valves.PULSE_INTERVAL
        timeout = self.valves.COGNITIVE_TIMEOUT

        try:
            # Start the request with a longer timeout
            self._emit_status(__event_emitter__, "üîÑ Waiting for Nervous System response...")

            # Thread-safe result storage using Lock
            result_lock = threading.Lock()
            result = {"response": None, "error": None, "done": False}

            def make_request():
                with requests.Session() as session:
                    try:
                        response = session.post(
                            url,
                            json=data,
                            headers={"Content-Type": "application/json"},
                            timeout=timeout
                        )
                        with result_lock:
                            result["response"] = response
                    except Exception as e:
                        with result_lock:
                            result["error"] = e
                    finally:
                        with result_lock:
                            result["done"] = True

            # Start request in daemon thread (will be cleaned up automatically)
            request_thread = threading.Thread(target=make_request, daemon=True)
            request_thread.start()

            # Emit pulse updates while waiting
            pulse_count = 0
            last_pulse_time = start_time

            while True:
                time.sleep(1)  # Check every second
                elapsed = time.time() - start_time

                # Check if request is done first (before timeout check)
                with result_lock:
                    is_done = result["done"]

                if is_done:
                    break

                # Check timeout
                if elapsed > timeout:
                    break

                # Emit pulse at regular intervals
                if time.time() - last_pulse_time >= pulse_interval:
                    pulse_count += 1
                    last_pulse_time = time.time()
                    self._emit_status(
                        __event_emitter__,
                        f"üîÑ Waiting for Nervous System... ({int(elapsed)}s elapsed)"
                    )

            # Wait for thread to complete (up to 5 seconds)
            request_thread.join(timeout=5)

            # Get final results with lock
            with result_lock:
                final_error = result["error"]
                final_response = result["response"]
                is_done = result["done"]

            if final_error:
                raise final_error

            if not is_done or final_response is None:
                raise requests.exceptions.Timeout("Request did not complete")

            response = final_response
            elapsed_total = time.time() - start_time

            self._emit_status(
                __event_emitter__,
                f"‚úÖ Cognitive query complete ({int(elapsed_total)}s)",
                done=True
            )

            if response.status_code == 200:
                # Return raw JSON for LLM to interpret
                try:
                    response_data = response.json()
                    # Check if response is empty or missing expected data
                    if not response_data or response_data == {}:
                        return (
                            f"‚ö†Ô∏è Workflow '{workflow_id}' returned an empty response.\n\n"
                            f"This may indicate:\n"
                            f"1. The workflow completed but produced no output\n"
                            f"2. The workflow needs a 'Respond to Webhook' node to return data\n"
                            f"3. The workflow configuration may need adjustment\n\n"
                            f"Check the n8n dashboard for workflow execution details."
                        )
                    return json.dumps(response_data, indent=2)
                except json.JSONDecodeError:
                    return response.text
            else:
                response_text = response.text
                max_len = 500
                display_text = response_text[:max_len]
                if len(response_text) > max_len:
                    display_text += "... [truncated]"
                return (
                    f"‚ö†Ô∏è Workflow returned status {response.status_code}\n\n"
                    f"Response: {display_text}"
                )

        except requests.exceptions.Timeout:
            elapsed = time.time() - start_time
            self._emit_status(__event_emitter__, f"‚è±Ô∏è Timeout after {int(elapsed)}s", done=True)
            return (
                f"‚è±Ô∏è Cognitive Query Timeout\n\n"
                f"**Workflow**: `{workflow_id}`\n"
                f"**Elapsed**: {int(elapsed)} seconds\n"
                f"**Limit**: {timeout} seconds\n\n"
                f"The workflow is taking longer than expected. It may still be running.\n"
                f"Check n8n dashboard or try again later."
            )

        except requests.exceptions.ConnectionError:
            self._emit_status(__event_emitter__, "‚ùå Connection failed", done=True)
            return (
                f"‚ùå Nervous System Unreachable\n\n"
                f"Cannot connect to n8n at `{url}`\n\n"
                f"Ensure the n8n container is running."
            )

        except Exception as e:
            self._emit_status(__event_emitter__, "‚ùå Error", done=True)
            return f"‚ùå Cognitive Query Error: {str(e)}"

    def list_workflows(
        self,
        __user__: dict = {},
        __event_emitter__: Callable[[dict], Any] = None,
    ) -> str:
        """
        Lists available n8n workflows and their operational modes.

        Returns documentation on available workflows and how to use them
        with either trigger_reflex() or query_workflow().
        
        Also includes connection diagnostics to help troubleshoot issues.
        """
        
        # Test connection to n8n
        connection_status = "‚úÖ Connected"
        try:
            # Construct health check URL more robustly
            base_url = self.valves.N8N_WEBHOOK_URL
            if '/webhook' in base_url:
                health_url = base_url.replace('/webhook', '/healthz')
            else:
                # If URL doesn't contain /webhook, assume it's a base URL
                health_url = base_url.rstrip('/') + '/healthz'
            
            response = requests.get(health_url, timeout=5)
            if response.status_code != 200:
                connection_status = f"‚ö†Ô∏è  Connection issue (status: {response.status_code})"
        except requests.exceptions.ConnectionError:
            connection_status = "‚ùå Cannot connect to n8n"
        except requests.exceptions.Timeout:
            connection_status = "‚è±Ô∏è Connection timeout"
        except Exception as e:
            connection_status = f"‚ùå Error: {str(e)}"

        return f"""
# n8n Reflex Arc - Available Workflows & Status

## Connection Status
{connection_status}
- Webhook URL: `{self.valves.N8N_WEBHOOK_URL}`
- Cognitive Timeout: {self.valves.COGNITIVE_TIMEOUT}s
- Reflex Timeout: {self.valves.REFLEX_TIMEOUT}s

## üî• Reflex Workflows (Fire-and-Forget)
Use `trigger_reflex(workflow_id, payload)` for these:

| Workflow | Webhook ID | Purpose |
|----------|------------|---------|
| Send Email | `send-email` | Send emails via SMTP |
| Slack Notify | `slack-notify` | Post to Slack channels |
| Telegram Send | `telegram-send` | Send Telegram messages |

## üß† Cognitive Workflows (Wait for Response)
Use `query_workflow(workflow_id, payload)` for these:

| Workflow | Webhook ID | Purpose |
|----------|------------|---------|
| Research Agent | `research` | Deep research with sources |
| OpenWebUI Action | `openwebui-action` | General-purpose router |

## ‚è∞ Scheduled Workflows (Autonomous)
These run automatically, no trigger needed:

| Workflow | Schedule | Purpose |
|----------|----------|---------|
| Morning Briefing | 8:00 AM daily | Tech news summary |
| RSS Monitor | Every 6 hours | Feed digest |
| Daily Report | 6:00 PM daily | Intelligence report |

## Usage Examples

**Fire-and-forget (email):**
```
trigger_reflex("send-email", '{{"to": "user@example.com", "subject": "Hello", "body": "..."}}')
```

**Cognitive query (research):**
```
query_workflow("research", "Latest developments in quantum computing")
```

## Troubleshooting

If you see connection errors:
1. Check that n8n is running: `docker ps | grep rin-reflex`
2. Verify workflows are activated in n8n: http://localhost:5678
3. Ensure webhook URLs match the workflow IDs
4. Check n8n logs: `docker logs rin-reflex-automation`

## Configuration

Timeouts can be adjusted in the tool's Valves settings:
- Cognitive Timeout: {cognitive_timeout}s (default: 300s)
- Reflex Timeout: {reflex_timeout}s (default: 10s)
""".format(
            cognitive_timeout=self.valves.COGNITIVE_TIMEOUT,
            reflex_timeout=self.valves.REFLEX_TIMEOUT
        )
